---
title: "23 - ANOVA 1 factor y comparaciones m√∫ltiples"
output: html_notebook
---

Una descripci√≥n completa que puede encontrar on line.

-   Joaqu√≠n Amat Rodrigo (2016). ANOVA an√°lisis de varianza para comparar m√∫ltiples medias.
<https://cienciadedatos.net/documentos/19_anova>

```{r}
library(tidyverse)
```

# ANOVA para un factor

Para realizar un ANOVA usamos la funci√≥n aov(), que tiene como primer par√°metro el modelo lineal que deseamos evaluar. El modelo lineal gen√©rico es:

$$
Y_{ij} = \mu + \alpha_i + \epsilon_{ij}
$$

Donde:

-   Y es la variable respuesta.
-   ùùÅ es la media de todos los datos juntos
-   ùú∂ es el efecto de grupo (del i√©simo grupo).
-   ùüÑ es el residual del individuo j√©simo perteneciente al i√©simo grupo. Se asume que los residuales tienen distribuci√≥n normal con media 0 y varianza sigma cuadrado:

$$
\epsilon_{ij} \sim N(0, \sigma^2)
$$


La hip√≥tesis a probar en un ANOVA de un factor es la siguiente:


$$
H_0: \alpha_1 = \alpha_2 = \dots = \alpha_k = 0 \\
H_1: \text{Al menos uno de los } \alpha_i \neq 0
$$

Para realizar el an√°lisis de varianza, se dividen las sumas de cuadrados en dos componentes:

$$
SC_{Total} = SC_{Entre} + SC_{Dentro}
$$

SC_{Total}: Suma de cuadrados total, que mide la variabilidad total de los datos.
SC_{Entre}: Suma de cuadrados entre grupos, que mide la variabilidad explicada por las diferencias entre los grupos.
SC_{Dentro}: Suma de cuadrados dentro de los grupos, que mide la variabilidad dentro de los grupos.


El estad√≠stico F se calcula como:

$$
F = \frac{\frac{SC_{Entre}}{gl_{Entre}}}{\frac{SC_{Dentro}}{gl_{Dentro}}}
$$

Donde:

gl_{Entre} = k - 1 es el grado de libertad entre los grupos (k es la cantidad de grupos).
gl_{Dentro} = N - k es el grado de libertad dentro de los grupos (N es el tama√±o de todas las muestra juntas).

Usaremos los datos de iris. Primero probamos con ancho de s√©palos, y luego puede hacerlo con largo de p√©talos para ver las diferencias.

```{r}
anovaModel <- aov(Sepal.Width ~ Species, data = iris)
# anovaModel <- aov(Petal.Length ~ Species, data = iris)
summary(anovaModel)
```

```{r}
anovaModel$coefficients
```


Tambi√©n puede realizarse con la funci√≥n lm(), que se refiere a modelos lineales (Linear Model). Aqu√≠ se puede ver en la √∫ltima l√≠nea que el estad√≠stico de prueba, los grados de libertad y el p-value coinciden con el resultado de aov(), ya que est√°n calculados para el modelo completo. Adem√°s se puede ver que los coeficientes son los mismos. 

El R¬≤ es el coeficiente de correlaci√≥n (no el de Pearson, porque la variable explicatoria es categ√≥rica). lm() es m√°s correcto usarlo para regresi√≥n lineal, es decir cuando la variable explicatoria es num√©rica (el tema se abordar√° m√°s adelante).

```{r}
lmModel <- lm(Sepal.Width ~ Species, data = iris)
# lmModel <- lm(Petal.Length ~ Species, data = iris)
summary(lmModel)
```

## Verificaci√≥n de supuestos

Siempre que se hace un an√°lisis es necesario verificar que se cumpla con los supuestos sobre los cuales se desarrroll√≥ el m√©todo. Por esa raz√≥n veremos seguidamente c√≥mo verificar los supuestos de ANOVA.

El siguiente v√≠nculo aborda este tema m√°s extensamente.

Mark Greenwood (2022). "ANOVA model diagnostics including QQ-plots"
<https://stats.libretexts.org/Bookshelves/Advanced_Statistics/Intermediate_Statistics_with_R_(Greenwood)/03%3A_One-Way_ANOVA/3.04%3A_ANOVA_model_diagnostics_including_QQ-plots>

### Normalidad

El an√°lisis supone que los residuales tienen distribuci√≥n Normal, por lo tanto realizamos un test T para una H0 que dice que la distribuci√≥n de los residuales no difiere de la distribuci√≥n Normal. Si el p-value es inferior a 0.05, la diferncia entre las distribuciones es diferente de cero, lo que significa que llos residuales no tienen distribuci√≥n Normal, y en ese caso no puedo aceptar los resultados del ANOVA.

```{r}
shapiro.test(residuals(anovaModel))
```

### Homogeneidad de varianzas

El an√°lisis supone que los residuales dentro de cada grupo tienen la misma varianza, por lo tanto realizamos un test T para una H0 que dice que todos los grupos tienen la misma varianza. Si el p-value es inferior a 0.05, hay al menos un grupo cuya varianza difiere del resto y en ese caso no puedo aceptar los resultados del ANOVA.

Existen muchos test posibles, todos son similares.  bartlett.test(), fligner.test(), var.test(), leveneTest()

```{r}
bartlett.test(Sepal.Width ~ Species, data = iris)
# bartlett.test(Petal.Length ~ Species, data = iris)
```

### Supuestos Gr√°ficamente

```{r}
par(mfrow = c(2,2))
plot(anovaModel, pch = 16)
```

```{r}
boxplot(anovaModel$residuals ~ iris$Species)
```


# Comparaciones m√∫ltiples

El siguiente v√≠nculo aborda este tema m√°s extensamente.

Joaqu√≠n Amat Rodrigo (2016). "Comparaciones m√∫ltiples: correcci√≥n de p-value y FDR".
<https://rpubs.com/Joaquin_AR/236898>


Las funciones LSD.test() y pairwise.t.test() puede usar los siguientes m√©todos: "holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr", "none" (T de Student)

## Intervalos LSD de Fisher (Least Significance Difference)

```{r}
library(agricolae)
lsdTest <- LSD.test(anovaModel, "Species", p.adj="none", alpha = 0.01, group=FALSE)
lsdTest
```

## Ajuste de Bonferroni

```{r}
pairwise.t.test(iris$Sepal.Width, iris$Species, p.adjust.method = "bonferroni")
```

## Ajuste de Holm-Bonferroni

```{r}
pairwise.t.test(iris$Sepal.Width, iris$Species, p.adjust.method = "holm")
```

## Tukey-Kramer (HSD). Honest Significant Difference. Tambi√©n conocido como correcci√≥n de Dunnet.

```{r}
tukeyTest <- TukeyHSD(anovaModel)
tukeyTest
```

```{r}
plot(tukeyTest)
```


